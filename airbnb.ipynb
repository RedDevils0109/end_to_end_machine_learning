{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.model_selection import KFold   \n",
    "from statistics import mean\n",
    "import joblib\n",
    "from ydata_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gain data insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r'datasets\\airbnb.csv')\n",
    "\n",
    "\n",
    "\n",
    "# In[3]: STEP 3. DISCOVER THE DATA TO GAIN INSIGHTS\n",
    "#region\n",
    "# 3.1 Quick view of the data\n",
    "print('\\n____________ Dataset info ____________')\n",
    "print(raw_data.info())              \n",
    "print('\\n____________ Some first data examples ____________')\n",
    "print(raw_data.head(3)) \n",
    "print('\\n____________ Counts on a feature ____________')\n",
    "#print(raw_data['LEGAL DOCUMENTS'].value_counts()) \n",
    "print('\\n____________ Statistics of numeric features ____________')\n",
    "print(raw_data.describe())    \n",
    "print('\\n____________ Get specific rows and cols ____________')     \n",
    "print(raw_data.iloc[[0,5,48], [2, 5]] ) # Refer using column ID\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "bins = [0, 100, 200, 300, 400, 500, 1000, 1500, 2000, 2500, np.inf]\n",
    "labels = ['0-100', '100-200', '200-300', '300-400', '400-500', '500-1000', '1000-1500', '1500-2000', '2000-2500', '2500+']\n",
    "\n",
    "# Categorize the realSum data according to the bins (only for visualization)\n",
    "binned_data = pd.cut(raw_data['realSum'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "## Plot the distribution of the realSum for Price range\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=binned_data, order=labels)\n",
    "plt.title('Distribution of realSum ')\n",
    "plt.xlabel('realSum Range')\n",
    "plt.ylabel('Frequency')\n",
    "# Save the plot to a file\n",
    "plt.savefig('figures/realSum_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Mean realSum of each city\n",
    "# Group by 'city' and calculate the mean of 'realSum'\n",
    "mean_realSum_by_city = raw_data.groupby('city')['realSum'].mean().sort_values()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "mean_realSum_by_city.plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Mean realSum')\n",
    "plt.title('Mean realSum by City')\n",
    "plt.xticks(rotation=45)  # Rotate x labels for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "# Import the ProfileReport class from the ydata_profiling package\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Create a ProfileReport object to generate an exploratory data analysis report\n",
    "report = ProfileReport(\n",
    "    raw_data,  # The DataFrame containing the raw data to be analyzed\n",
    "    title=\"Airbnb prices in European cities:\",  # Title for the report\n",
    "\n",
    "    # Custom descriptions for variables in the dataset to provide context in the report\n",
    "    variables={\n",
    "        \"description\": {\n",
    "            \"city\": \"The city where the accommodation offer is located.\",  # Description for the 'city' column\n",
    "            \"realSum\": \"The total price in EUR for accommodating two people for two nights.\",  # Description for the 'realSum' column\n",
    "            \"room_type\": \"The type of accommodation being offered (e.g., entire place, private room, shared room).\",  # Description for the 'room_type' column\n",
    "            \"room_shared\": \"Binary variable indicating if the room is shared (1 for shared, 0 for not).\",  # Description for the 'room_shared' column\n",
    "            \"room_private\": \"Binary variable indicating if the room is private (1 for private, 0 for not).\",  # Description for the 'room_private' column\n",
    "            \"person_capacity\": \"The maximum number of guests that the accommodation can host.\",  # Description for the 'person_capacity' column\n",
    "            \"host_is_superhost\": \"Binary variable indicating if the host is a superhost (1 for superhost, 0 for not).\",  # Description for the 'host_is_superhost' column\n",
    "            \"multi\": \"Binary variable indicating if the listing is managed by a host with 2-4 offers (1 for yes, 0 for no).\",  # Description for the 'multi' column\n",
    "            \"biz\": \"Binary variable indicating if the listing is managed by a host with more than 4 offers (1 for yes, 0 for no).\",  # Description for the 'biz' column\n",
    "            \"cleanliness_rating\": \"Rating of the cleanliness of the accommodation, usually on a scale (e.g., 1 to 10).\",  # Description for the 'cleanliness_rating' column\n",
    "            \"guest_satisfaction_overall\": \"Overall rating given by guests for the listing, typically on a scale (e.g., 1 to 10).\",  # Description for the 'guest_satisfaction_overall' column\n",
    "            \"bedrooms\": \"Number of bedrooms in the accommodation (0 for studios).\",  # Description for the 'bedrooms' column\n",
    "            \"dist\": \"Distance from the city center in kilometers.\",  # Description for the 'dist' column\n",
    "            \"metro_dist\": \"Distance from the nearest metro station in kilometers.\",  # Description for the 'metro_dist' column\n",
    "            \"attr_index\": \"Index indicating the attractiveness of the listing location based on nearby attractions.\",  # Description for the 'attr_index' column\n",
    "            \"attr_index_norm\": \"Normalized attractiveness index (scaled between 0 and 100).\",  # Description for the 'attr_index_norm' column\n",
    "            \"rest_index\": \"Index indicating the restaurant options available near the listing location.\",  # Description for the 'rest_index' column\n",
    "            \"rest_index_norm\": \"Normalized restaurant index (scaled between 0 and 100).\",  # Description for the 'rest_index_norm' column\n",
    "            \"lng\": \"Longitude coordinate of the listing location.\",  # Description for the 'lng' column\n",
    "            \"lat\": \"Latitude coordinate of the listing location.\"  # Description for the 'lat' column\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Display the report in a notebook if possible\n",
    "report.to_notebook_iframe()\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = raw_data.corr(numeric_only=True)\n",
    "\n",
    "# Extract the correlation of 'realSum' with other variables\n",
    "corr_realSum = corr_matrix[['realSum']]\n",
    "\n",
    "# Sort the correlations in descending order\n",
    "sorted_columns = corr_realSum.sort_values(by='realSum', ascending=False).index\n",
    "sorted_corr_realSum = corr_realSum.loc[sorted_columns]\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(sorted_corr_realSum, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation with realSum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "raw_data.drop(columns=[\"attr_index\", \"rest_index\", \"_id\"], inplace=True)\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = raw_data[\"realSum\"].quantile(0.25)\n",
    "Q3 = raw_data[\"realSum\"].quantile(0.75)\n",
    "\n",
    "# Calculate the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bound to identify outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the outliers from the training set\n",
    "raw_data = raw_data[(raw_data[\"realSum\"] >= lower_bound) & (raw_data[\"realSum\"] <= upper_bound)]\n",
    "\n",
    "\n",
    "binned_data = pd.cut(raw_data['realSum'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Plot the distribution of the binned realSum\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=binned_data, order=labels)\n",
    "plt.title('Distribution of realSum (After remove outlier)')\n",
    "plt.xlabel('realSum Range')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('figures/realSum_distribution_after.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "\n",
    "method = 2\n",
    "if method == 1: # Method 1: Randomly select 20% of data for test set. Used when data set is large\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_set, test_set = train_test_split(raw_data, test_size=0.2, random_state=42)\n",
    "else:  #Stratified split\n",
    "# Define bins and labels for stratification\n",
    "    bins = [0, 100, 200, 300, 400, 500, np.inf]\n",
    "    labels = ['0-100', '100-200', '200-300', '300-400', '400-500', '500+']\n",
    "\n",
    "# Create the 'PRICE RANGE' column for stratification\n",
    "    raw_data[\"PRICE RANGE\"] = pd.cut(raw_data[\"realSum\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Perform stratified split based on 'PRICE RANGE'\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "    for train_index, test_index in splitter.split(raw_data, raw_data[\"PRICE RANGE\"]):\n",
    "        train_set = raw_data.iloc[train_index].copy()\n",
    "        test_set = raw_data.iloc[test_index].copy()\n",
    "    \n",
    "# Drop the 'PRICE RANGE' column after stratified split\n",
    "    \n",
    "    train_set.drop(columns=\"PRICE RANGE\", inplace=True)\n",
    "    test_set.drop(columns=\"PRICE RANGE\", inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data after split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_labels = train_set[\"realSum\"].copy()\n",
    "train_set = train_set.drop(columns=\"realSum\")\n",
    "\n",
    "\n",
    "test_set_labels = test_set[\"realSum\"].copy()\n",
    "test_set = test_set.drop(columns=\"realSum\")\n",
    "\n",
    "print('\\n____________ Split training and test set ____________')     \n",
    "print(len(train_set), \"training +\", len(test_set), \"test examples\")\n",
    "print(train_set.head(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 4.4 Define pipelines for processing data. \n",
    "# INFO: Pipeline is a sequence of transformers (see Geron 2019, page 73). For step-by-step manipulation, see Details_toPipeline.py \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# 4.4.1 Define ColumnSelector: a transformer for choosing columns\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "    def fit(self, dataframe, labels=None):\n",
    "        return self\n",
    "    def transform(self, dataframe):\n",
    "        return dataframe[self.feature_names].values   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "\n",
    "\n",
    "cat_feat_names = list(train_set.select_dtypes(exclude=[np.number, bool]).columns)  #Categories column\n",
    "\n",
    "# Combine numerical and boolean features into num_feat_names\n",
    "\n",
    "print(\"Categorical features:\", cat_feat_names)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define category pipelines\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(cat_feat_names)), # Select categorical features\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"constant\", fill_value=\"NO INFO\", copy=True)),  # Handle missing values\n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # One-hot encode categorical features\n",
    "])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_feat_names = list(train_set.select_dtypes(include=[np.number]).columns) #Numerical column\n",
    "\n",
    "print(\"Numerical features:\", num_feat_names)\n",
    "\n",
    "# Define numerical pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(num_feat_names)), #select numerical feature\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy=\"median\", copy=True)), #Handle missing value\n",
    "    ('std_scaler', StandardScaler(with_mean=True, with_std=True, copy=True)) #Scale feature\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "bool_feat_names = list(train_set.select_dtypes(include=[bool]).columns)   #Boolean column\n",
    "print(\"Boolean features:\", bool_feat_names)\n",
    "def boolean_to_binary(X):\n",
    "    return X.astype(int)\n",
    "# Define boolean pipelines\n",
    "bool_pipeline = Pipeline([\n",
    "    ('selector', ColumnSelector(bool_feat_names)),  # Select boolean features\n",
    "    ('to_binary', FunctionTransformer(boolean_to_binary, validate=False)),  # Convert boolean to binary\n",
    "\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
    "  \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "# Combine the pipelines\n",
    "full_pipeline = ColumnTransformer([ #Combined pipeline\n",
    "    (\"num_pipeline\", num_pipeline, num_feat_names),\n",
    "    (\"cat_pipeline\", cat_pipeline, cat_feat_names),\n",
    "    (\"bool_pipeline\", bool_pipeline, bool_feat_names)\n",
    "])\n",
    "\n",
    "\n",
    "processed_train_set_val = full_pipeline.fit_transform(train_set)\n",
    "joblib.dump(full_pipeline, r'models/full_pipeline.pkl')\n",
    "\n",
    "# Collect feature names\n",
    "num_feature_names = num_feat_names\n",
    "cat_feature_names = full_pipeline.named_transformers_['cat_pipeline'].named_steps['cat_encoder'].get_feature_names_out(cat_feat_names)\n",
    "bool_feature_names = bool_feat_names  \n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names = list(num_feature_names) + list(cat_feature_names) + list(bool_feature_names)\n",
    "\n",
    "# Convert to DataFrame\n",
    "transformed_df = pd.DataFrame(processed_train_set_val, columns=all_feature_names)\n",
    "\n",
    "# View the info and the  first few rows\n",
    "print('\\n____________ Processed feature values ____________')\n",
    "print(transformed_df.info())\n",
    "print(transformed_df.head())\n",
    "\n",
    "print(\"Shape of the processed data:\", transformed_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def store_model(model, model_name = \"\"):\n",
    "    # NOTE: sklearn.joblib faster than pickle of Python\n",
    "    # INFO: can store only ONE object in a file\n",
    "    if model_name == \"\": \n",
    "        model_name = type(model).__name__\n",
    "    joblib.dump(model,'models/' + model_name + '_model.pkl')\n",
    "def load_model(model_name):\n",
    "    # Load objects into memory\n",
    "    \n",
    "    model = joblib.load('models/' + model_name + '_model.pkl')\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Score and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1.2 Compute R2 score and root mean squared error\n",
    "def r2score_and_rmse(model, train_data, labels): \n",
    "    r2score = model.score(train_data, labels)\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    prediction = model.predict(train_data)\n",
    "    mse = mean_squared_error(labels, prediction)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return r2score, rmse   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(processed_train_set_val, train_set_labels)\n",
    "print('\\n____________ LinearRegression ____________')\n",
    "print('Learned parameters: ', model.coef_, model.intercept_)\n",
    "\n",
    "# Compute R2 score and root mean squared error\n",
    "r2score, rmse = r2score_and_rmse(model, processed_train_set_val, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "        \n",
    "#  Predict labels for some training instances\n",
    "print(\"\\nInput data: \\n\", train_set.iloc[0:9])\n",
    "print(\"\\nPredictions: \", model.predict(processed_train_set_val[0:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[0:9]))\n",
    "store_model(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polinominal Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_feat_adder = PolynomialFeatures(degree = 2) # add high-degree features to the data\n",
    "train_set_poly_added = poly_feat_adder.fit_transform(processed_train_set_val)\n",
    "new_training = 10\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_set_poly_added, train_set_labels)\n",
    "    \n",
    "\n",
    "#  Compute R2 score and root mean squared error\n",
    "print('\\n____________ Polinomial regression ____________')\n",
    "r2score, rmse = r2score_and_rmse(model, train_set_poly_added, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "# Predict labels for some training instances\n",
    "print(\"\\nPredictions: \", model.predict(train_set_poly_added[0:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[0:9]))\n",
    "\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 100) # n_estimators: no. of trees\n",
    "model.fit(processed_train_set_val, train_set_labels)\n",
    "\n",
    "\n",
    "# Compute R2 score and root mean squared error\n",
    "print('\\n____________ RandomForestRegressor ____________')\n",
    "r2score, rmse = r2score_and_rmse(model, processed_train_set_val, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "   \n",
    "# Predict labels for some training instances\n",
    "#print(\"Input data: \\n\", train_set.iloc[0:9])\n",
    "print(\"\\nPredictions: \", model.predict(processed_train_set_val[0:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[0:9]))\n",
    "\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = GradientBoostingRegressor(n_estimators=100)  # You can adjust n_estimators and other hyperparameters\n",
    "model.fit(processed_train_set_val, train_set_labels)\n",
    "\n",
    "# Compute R2 score and root mean squared error\n",
    "print('\\n____________ GradientBoostingRegressor ____________')\n",
    "r2score, rmse = r2score_and_rmse(model, processed_train_set_val, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "\n",
    "# Predict labels for some training instances\n",
    "print(\"\\nPredictions: \", model.predict(processed_train_set_val[0:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[0:9]))\n",
    "\n",
    "# Store the model\n",
    "store_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = ExtraTreesRegressor(n_estimators=100)  # # n_estimators: no. of trees\n",
    "model.fit(processed_train_set_val, train_set_labels)\n",
    "\n",
    "# Compute R2 score and root mean squared error\n",
    "print('\\n____________ ExtraTreesRegressor ____________')\n",
    "r2score, rmse = r2score_and_rmse(model, processed_train_set_val, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "\n",
    "# Predict labels for some training instances\n",
    "print(\"\\nPredictions: \", model.predict(processed_train_set_val[0:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(train_set_labels[0:9]))\n",
    "\n",
    "# Store the model\n",
    "store_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=5)  # You can adjust n_neighbors and other hyperparameters\n",
    "model.fit(processed_train_set_val, train_set_labels)\n",
    "\n",
    "# Compute R2 score and root mean squared error\n",
    "print('\\n____________ KNeighborsRegressor ____________')\n",
    "r2score, rmse = r2score_and_rmse(model, processed_train_set_val, train_set_labels)\n",
    "print('\\nR2 score (on training data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "\n",
    "# Predict labels for some training instances\n",
    "print(\"\\nPredictions: \", model.predict(processed_train_set_val[0:9]))\n",
    "print(\"Labels:      \", list(train_set_labels[0:9]))\n",
    "\n",
    "# Store the model\n",
    "store_model(model, 'KNeighborsRegressor')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate with K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def evaluate_model(model, model_name, feature, label, cv):\n",
    "    # Perform K-fold cross-validation on the model, using negative mean squared error (NMSE) as the scoring metric\n",
    "    nmse_scores = cross_val_score(model, feature, label, cv=cv, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Convert NMSE to RMSE (Root Mean Squared Error) by taking the square root of the negative scores\n",
    "    rmse_scores = np.sqrt(-nmse_scores)\n",
    "    \n",
    "    # Save the RMSE scores for future reference\n",
    "    joblib.dump(rmse_scores, f'saved_objects/{model_name}_rmse.pkl')\n",
    "    \n",
    "    \n",
    "    print(f\"{model_name} RMSE: \", rmse_scores.round(decimals=1))\n",
    "    \n",
    "   \n",
    "    print(\"Avg. RMSE: \", np.mean(rmse_scores).round(decimals=1), '\\n')\n",
    "\n",
    "# Define a dictionary of models to evaluate, with each key being the model name and the value being the model object\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),  #\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(n_estimators=100),  \n",
    "    \"PolynomialRegression\": Pipeline([  \n",
    "        ('poly_feat_adder', PolynomialFeatures(degree=2)),  \n",
    "        ('lin_reg', LinearRegression())\n",
    "    ]),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(), \n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=5), \n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(n_estimators=100)  \n",
    "}\n",
    "\n",
    "# Set up K-Fold cross-validation with 5 splits, shuffling the data before splitting\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=37)\n",
    "\n",
    "print('\\n____________ K-fold cross-validation ____________')\n",
    "\n",
    "# Flag to indicate whether to run new evaluations or load existing results\n",
    "run_new_evaluation = 1\n",
    "\n",
    "if run_new_evaluation:\n",
    "    # If running new evaluations, iterate through each model in the dictionary\n",
    "    for model_name, model in models.items():\n",
    "        feature = processed_train_set_val  # The features to use in the model\n",
    "        evaluate_model(model, model_name, feature, train_set_labels, cv)  # Evaluate each model using the helper function\n",
    "else:\n",
    "    # If not running new evaluations, load the saved RMSE scores and print them\n",
    "    for model_name in models.keys():\n",
    "        try:\n",
    "            # Try to load the saved RMSE scores for the model\n",
    "            rmse_scores = joblib.load(f'saved_objects/{model_name}_rmse.pkl')\n",
    "            print(f\"{model_name} RMSE: \", rmse_scores.round(decimals=1))\n",
    "            print(\"Avg. RMSE: \", np.mean(rmse_scores).round(decimals=1), '\\n')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"No saved RMSE scores found for {model_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Just for testing , not complete code \"\"\"\n",
    "#%% 7.3 Run on test data\n",
    "best_model = ExtraTreesRegressor(n_estimators=100)  # You can adjust max_iter and other hyperparameters\n",
    "best_model.fit(processed_train_set_val, train_set_labels)\n",
    "full_pipeline = joblib.load(r'models/full_pipeline.pkl')\n",
    "\n",
    "\n",
    "processed_test_set = full_pipeline.transform(test_set)  \n",
    "# 7.3.1 Compute R2 score and root mean squared error\n",
    "r2score, rmse = r2score_and_rmse(best_model, processed_test_set, test_set_labels)\n",
    "print('\\nPerformance on test data:')\n",
    "print('R2 score (on test data, best=1):', r2score)\n",
    "print(\"Root Mean Square Error: \", rmse.round(decimals=1))\n",
    "# 7.3.2 Predict labels for some test instances\n",
    "print(\"\\nTest data: \\n\", test_set.iloc[0:9])\n",
    "print(\"\\nPredictions: \", best_model.predict(processed_test_set[0:9]).round(decimals=1))\n",
    "print(\"Labels:      \", list(test_set_labels[0:9]),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE-TUNE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # Used for saving and loading models so we don't have to re-run searches every time\n",
    "import numpy as np  # For mathematical operations, like calculating square root of errors\n",
    "from sklearn.ensemble import ExtraTreesRegressor  # This is the machine learning model we're using\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold  # Functions to fine-tune our model\n",
    "from scipy.stats import randint, uniform  # For generating random distributions during hyperparameter tuning\n",
    "\n",
    "# Function to print out the results of the hyperparameter search\n",
    "def print_search_result(grid_search, model_name=\"\"):\n",
    "    # Heading to indicate what model we're fine-tuning\n",
    "    print(\"\\n====== Fine-tune \" + model_name + \" ======\")\n",
    "    # Output the best combination of hyperparameters found\n",
    "    print('Best hyperparameter combination: ', grid_search.best_params_)\n",
    "    # Output the best RMSE (root mean squared error), a performance metric\n",
    "    print('Best rmse: ', np.sqrt(-grid_search.best_score_))\n",
    "    # Print out the performance of all the hyperparameter combinations that were tested\n",
    "    print('Performance of hyperparameter combinations:')\n",
    "    cv_results = grid_search.cv_results_  # Get all the results from cross-validation\n",
    "    for (mean_score, params) in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "        # Print the RMSE for each combination of parameters, rounded to 1 decimal place\n",
    "        print('rmse =', np.sqrt(-mean_score).round(decimals=1), params)\n",
    "\n",
    "method = 2  # Switch between 1 (for GridSearchCV) and 2 (for RandomizedSearchCV)\n",
    "# Method 2 is recommended as method 1 can be computationally expensive for many hyperparameters\n",
    "\n",
    "# Set up cross-validation using KFold\n",
    "# Splits the data into 5 parts (folds) and shuffles it to avoid bias, random_state ensures results are repeatable\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=37)\n",
    "\n",
    "# If we're using Method 1: GridSearchCV\n",
    "if method == 1:\n",
    "    run_new_search = True  # Decide whether to run a new search or load previous results\n",
    "\n",
    "    if run_new_search:\n",
    "        # Define the grid of hyperparameters to test\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "            'max_features': ['sqrt', 'log2', None, 0.5, 0.8],  # How many features to consider when looking for the best split\n",
    "            'max_depth': [10, 20, 50, 100],  # Maximum depth of each tree\n",
    "            'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "            'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required at a leaf node\n",
    "            'bootstrap': [True, False],  # Whether bootstrap sampling is used (random sampling with replacement)\n",
    "        }\n",
    "\n",
    "        # Initialize the ExtraTreesRegressor model\n",
    "        model = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "        # Set up the GridSearchCV to try out all combinations of hyperparameters\n",
    "        # GridSearchCV will use cross-validation to evaluate the performance of each combination\n",
    "        # We're using negative mean squared error as the scoring metric\n",
    "        \n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='neg_mean_squared_error', \n",
    "                                   return_train_score=True, n_jobs=-1, refit=True)\n",
    "\n",
    "        # Fit the model to the training data (processed_train_set_val and train_set_labels should be defined elsewhere)\n",
    "        grid_search.fit(processed_train_set_val, train_set_labels)\n",
    "\n",
    "        # Save the search results so we can load them later instead of running the search again\n",
    "        joblib.dump(grid_search, 'saved_objects/ExtraTreesRegressor_gridsearch.pkl')\n",
    "\n",
    "        # Print the results of the grid search\n",
    "        print_search_result(grid_search, model_name=\"ExtraTreesRegressor\")\n",
    "    else:\n",
    "        # Load previous search results\n",
    "        grid_search = joblib.load('saved_objects/ExtraTreesRegressor_gridsearch.pkl')\n",
    "        print_search_result(grid_search, model_name=\"ExtraTreesRegressor\")\n",
    "\n",
    "# If we're using Method 2: RandomizedSearchCV\n",
    "elif method == 2:\n",
    "    run_new_search = True  # Decide whether to run a new search or load previous results\n",
    "\n",
    "    if run_new_search:\n",
    "        # Define the random distribution of hyperparameters to sample from\n",
    "        param_distributions = {\n",
    "            'n_estimators': randint(50, 300),  # Randomly choose the number of trees\n",
    "            'max_features': ['sqrt', 'log2', None] + list(uniform(0.1, 0.9).rvs(size=5)),  # Randomly choose number of features\n",
    "            'max_depth': randint(5, 100),  # Randomly choose the tree depth\n",
    "            'min_samples_split': randint(2, 10),  # Randomly choose the minimum samples needed to split\n",
    "            'min_samples_leaf': randint(1, 10),  # Randomly choose the minimum samples needed at a leaf\n",
    "            'bootstrap': [True, False],  # Randomly decide whether to use bootstrap sampling\n",
    "        }\n",
    "\n",
    "        # Initialize the ExtraTreesRegressor model\n",
    "        model = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "        # Set up the RandomizedSearchCV to randomly sample hyperparameters\n",
    "        # RandomizedSearchCV will use cross-validation to evaluate the performance of each combination\n",
    "        # Each iteration will try a different combination of hyperparameters, randomized from the distributions\n",
    "        random_search = RandomizedSearchCV(model, param_distributions, n_iter=100, cv=cv, \n",
    "                                           scoring='neg_mean_squared_error', return_train_score=True, \n",
    "                                           random_state=42, n_jobs=-1, refit=True)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        random_search.fit(processed_train_set_val, train_set_labels)\n",
    "\n",
    "        # Save the search results\n",
    "        joblib.dump(random_search, 'saved_objects/ExtraTreesRegressor_randomsearch.pkl')\n",
    "\n",
    "        # Print the results of the random search\n",
    "        print_search_result(random_search, model_name=\"ExtraTreesRegressor\")\n",
    "    else:\n",
    "        # Load previous random search results\n",
    "        random_search = joblib.load('saved_objects/ExtraTreesRegressor_randomsearch.pkl')\n",
    "        print_search_result(random_search, model_name=\"ExtraTreesRegressor\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
